import { Queue } from "~/utils/queue.server";
import { openai } from "~/utils/providers.server";
import { logAPICall } from "~/routes/articles.new/logging.server";
import { LLMS } from "~/routes/articles.new/actions.server";
import { prisma } from "~/db.server";
import { zodResponseFormat } from "openai/helpers/zod";
import {
  extractLinksSystemPrompt,
  extractLinksUserPrompt,
  OutputSchema,
  validateExtractedLinks,
} from "~/routes/articles.new/link-extraction-prompts.server";

interface ExtractLinksJob {
  productId: string;
}

async function extractRelevantLinks(
  content: string,
  baseUrl: string,
  productId: string,
) {
  console.log(
    `\nüîó [extractRelevantLinks] EXTRACTING RELEVANT LINKS for product ${productId}`,
  );
  console.log(`üåê Base URL: ${baseUrl}`);
  console.log(`üìÑ Content length: ${content.length} characters`);

  const prompt = extractLinksUserPrompt({ baseUrl, content });
  console.log(`üß† Prompt generated. Length: ${prompt.length} characters`);

  try {
    console.log(`ü§ñ [extractRelevantLinks] Calling OpenAI API...`);

    const completion = await openai.beta.chat.completions.parse({
      model: "gpt-4o-mini",
      messages: [
        { role: "system", content: extractLinksSystemPrompt },
        { role: "user", content: prompt },
      ],
      temperature: 0,
      max_tokens: 16383,
      top_p: 1,
      frequency_penalty: 0,
      presence_penalty: 0,
      response_format: zodResponseFormat(OutputSchema, "extracted_links"),
    });

    console.log(`‚úÖ [extractRelevantLinks] OpenAI API call successful`);

    if (completion.choices[0].message.refusal) {
      console.log(
        `‚ö†Ô∏è [extractRelevantLinks] Model refused to respond:`,
        completion.choices[0].message.refusal,
      );
      return { links: [], productId };
    }

    const extractedLinks = completion.choices[0].message.parsed;
    const validatedLinks = validateExtractedLinks(extractedLinks);

    console.log(
      `üîç [extractRelevantLinks] RELEVANT LINKS EXTRACTED: ${validatedLinks.extracted_links.length} links found`,
    );
    console.log(`üìù [extractRelevantLinks] Logging API call...`);
    await logAPICall({
      llm: LLMS.EXTRACT_RELEVANT_LINKS,
      timestamp: new Date().toISOString(),
      model: "gpt-4o-mini",
      messages: [{ role: "user", content: prompt }],
      response: JSON.stringify(validatedLinks),
    });
    console.log(`‚úÖ [extractRelevantLinks] API call logged successfully`);

    return { links: validatedLinks.extracted_links, productId };
  } catch (error) {
    console.error(
      `‚ùå [extractRelevantLinks] ERROR EXTRACTING RELEVANT LINKS:`,
      error,
    );
    throw error;
  }
}

export const extractRelevantLinksQueue = Queue<ExtractLinksJob>(
  "extractRelevantLinks",
  async (job) => {
    console.log(
      `\nüöÄ [extractRelevantLinksQueue] Starting job for product ID: ${job.data.productId}`,
    );

    const { productId } = job.data;

    console.log(
      `üîç [extractRelevantLinksQueue] Fetching product from database...`,
    );
    const product = await prisma.product.findUnique({
      where: { id: productId },
      include: { scrapedWebsites: true },
    });

    if (!product || !product.scrapedWebsites[0]) {
      console.error(
        `‚ùå [extractRelevantLinksQueue] Product not found or has no data`,
      );
      throw new Error(`Product with id ${productId} not found or has no data`);
    }
    console.log(`‚úÖ [extractRelevantLinksQueue] Product found`);

    const content = product.scrapedWebsites[0].content;
    const baseUrl = product.baseUrl;

    if (!content) {
      console.error(`‚ùå [extractRelevantLinksQueue] Content not found`);
      throw new Error(`Content for product with id ${productId} not found`);
    }
    console.log(
      `üìÑ [extractRelevantLinksQueue] Content retrieved. Length: ${content.length} characters`,
    );
    console.log(`üåê [extractRelevantLinksQueue] Base URL: ${baseUrl}`);

    console.log(`üîó [extractRelevantLinksQueue] Extracting relevant links...`);
    const { links } = await extractRelevantLinks(content, baseUrl, productId);
    console.log(
      `‚úÖ [extractRelevantLinksQueue] Relevant links extracted successfully`,
    );

    console.log(`üèÅ [extractRelevantLinksQueue] Job completed successfully!`);
    // TODO - change Prisma schema so that relevantUrls is an array LinkSchema
    return {
      relevantUrls: [...links.map((link) => link.url).slice(0, 4)],
    };
  },
);
